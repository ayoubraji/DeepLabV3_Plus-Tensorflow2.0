{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"inference.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"TDyJJlehUyA3","colab_type":"code","outputId":"10d03d0f-cb0d-4240-a4db-e12e70fdc93a","executionInfo":{"status":"ok","timestamp":1561067842322,"user_tz":-120,"elapsed":46787,"user":{"displayName":"AYOUB RAJI","photoUrl":"","userId":"07525700700054333143"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["#Upload drive folders\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HXZH8nYwSy6z","colab_type":"code","outputId":"5e37ee7d-5df8-4021-a2c4-be8d448413f5","executionInfo":{"status":"ok","timestamp":1561067843894,"user_tz":-120,"elapsed":48341,"user":{"displayName":"AYOUB RAJI","photoUrl":"","userId":"07525700700054333143"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!ls"],"execution_count":2,"outputs":[{"output_type":"stream","text":["drive  sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xvjB32nqU0R_","colab_type":"code","outputId":"62e87d1a-310c-4237-cac3-ddf08b0b584e","executionInfo":{"status":"ok","timestamp":1561067845895,"user_tz":-120,"elapsed":50314,"user":{"displayName":"AYOUB RAJI","photoUrl":"","userId":"07525700700054333143"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["#Check the content of my notebooks folder\n","!ls drive/My\\ Drive/Colab\\ Notebooks/progetto2_visione/DeepLabV3_Plus-Tensorflow2.0/"],"execution_count":3,"outputs":[{"output_type":"stream","text":["1802.02611.pdf\t     deeplabv3plus.png\tinference.py   outputs\t    train.ipynb\n","cityscapes_dict.pkl  gifs\t\tlast_epoch.h5  __pycache__  train.py\n","deeplab.py\t     inference.ipynb\told_scripts    README.md    videos\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MS0JJWf-U2Ty","colab_type":"code","outputId":"91743b27-b689-4e0c-e54a-f74ac77f7942","executionInfo":{"status":"ok","timestamp":1561067845897,"user_tz":-120,"elapsed":50300,"user":{"displayName":"AYOUB RAJI","photoUrl":"","userId":"07525700700054333143"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#Set the actual directory\n","#!!!!!!!!!!!!!!!!!! Change it if you have an absolute path that is different !!!!!!!!!!!!!!!!!!!!!!!!\n","import os \n","import sys\n","os.chdir(\"/content/drive/My Drive/Colab Notebooks/progetto2_visione/\")\n","ROOT_DIR = os.getcwd()\n","print (ROOT_DIR)\n","os.chdir(os.path.join(ROOT_DIR, \"DeepLabV3_Plus-Tensorflow2.0/\"))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/progetto2_visione\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BCKr37puTVQu","colab_type":"code","outputId":"5f006282-ae9a-4704-ce18-bec8f3278af2","executionInfo":{"status":"ok","timestamp":1561067850160,"user_tz":-120,"elapsed":54545,"user":{"displayName":"AYOUB RAJI","photoUrl":"","userId":"07525700700054333143"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["import os\n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.python.keras.models import Model, load_model\n","from tensorflow.python.keras.preprocessing.image import load_img, img_to_array\n","from deeplab import DeepLabV3Plus\n","import tensorflow as tf\n","import cv2\n","from tqdm import tqdm\n","import os\n","import random\n","from glob import glob\n","import pickle\n","import time\n","import json\n","from tensorflow.keras.utils import multi_gpu_model\n","from tensorflow.python.keras.utils import Sequence\n","from moviepy.editor import VideoFileClip, ImageSequenceClip\n","from tensorflow.keras.applications.resnet50 import preprocess_input"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n","Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n","Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3080192/45929032 bytes (6.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b7290880/45929032 bytes (15.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b11583488/45929032 bytes (25.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b15704064/45929032 bytes (34.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b20054016/45929032 bytes (43.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b24109056/45929032 bytes (52.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b27721728/45929032 bytes (60.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b31932416/45929032 bytes (69.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b36159488/45929032 bytes (78.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b40361984/45929032 bytes (87.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b44646400/45929032 bytes (97.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n","  Done\n","File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"85P9uXFHTVQy","colab_type":"code","outputId":"4b4e3a1a-00e0-41f9-e4cf-17ba5cb1ef6c","executionInfo":{"status":"ok","timestamp":1561067850377,"user_tz":-120,"elapsed":54747,"user":{"displayName":"AYOUB RAJI","photoUrl":"","userId":"07525700700054333143"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["h, w = 1080, 1920\n","with open('cityscapes_dict.pkl', 'rb') as f:\n","    id_to_color = pickle.load(f)['color_map']\n","\n","# la strada è sette       \n","new_id_to_color = [0, 7, 11, 19, 20, 23, 24, 26, 27, 28, 32, 33] # quello che ci serve\n","\n","# id_col = [x for i in id_to_color: i in new_id_to_color]\n","\n","id_col = [id_to_color[x] for x in id_to_color if x in new_id_to_color]\n","\n","print (id_col)\n","\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["[(0, 0, 0), (128, 64, 128), (70, 70, 70), (250, 170, 30), (220, 220, 0), (70, 130, 180), (220, 20, 60), (0, 0, 142), (0, 0, 70), (0, 60, 100), (0, 0, 230), (119, 11, 32)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7z6WGDSLTVQ1","colab_type":"code","outputId":"7f22da98-62d8-444a-d14a-fa57830bab13","executionInfo":{"status":"error","timestamp":1561067973799,"user_tz":-120,"elapsed":7156,"user":{"displayName":"AYOUB RAJI","photoUrl":"","userId":"07525700700054333143"}},"colab":{"base_uri":"https://localhost:8080/","height":428}},"source":["model = DeepLabV3Plus(h, w, 34)\n","#model.load_weights('top_weights.h5')\n","model.load_weights('last_epoch.h5')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["*** Building DeepLabv3Plus Network ***\n"],"name":"stdout"},{"output_type":"stream","text":["W0620 21:59:29.818314 140545828964224 warnings.py:99] /usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n","  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n","\n"],"name":"stderr"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-3373dbbe0b16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepLabV3Plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m34\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#model.load_weights('top_weights.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'last_epoch.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/Colab Notebooks/progetto2_visione/DeepLabV3_Plus-Tensorflow2.0/deeplab.py\u001b[0m in \u001b[0;36mDeepLabV3Plus\u001b[0;34m(img_height, img_width, nclasses)\u001b[0m\n\u001b[1;32m     67\u001b[0m         img_height, img_width, 3), weights='imagenet', include_top=False)\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mimage_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'activation_39'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mx_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mASPP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mx_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUpsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_height\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_width\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mget_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m    565\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No such layer: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: No such layer: activation_39"]}]},{"cell_type":"code","metadata":{"id":"7Hz14vCkTVQ8","colab_type":"code","colab":{}},"source":["def pipeline(image, return_seg=False):\n","    global b\n","    alpha = 0.5\n","    dims = image.shape\n","    image = cv2.resize(image, (w, h))\n","    x = image.copy()\n","    z = model.predict(preprocess_input(np.expand_dims(x, axis=0)))\n","    z = np.squeeze(z)\n","    y = np.argmax(z, axis=2)\n","    \n","    img_color = image.copy()   \n","    for i in np.unique(y):\n","        if i in id_to_color:\n","            img_color[y==i] = id_to_color[i]\n","\n","    if return_seg:\n","        cv2.addWeighted(image, alpha, img_color, 1-alpha, 0, img_color)\n","        return img_color, y\n","    else:\n","        cv2.addWeighted(image, alpha, img_color, 1-alpha, 0, img_color)      \n","        return img_color"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8FCZ7D90bR47","colab_type":"code","colab":{}},"source":["def clean_segmentation(seg):\n","  \n","  #only moving objects\n","  mo_id_to_color = [24,25,26,27,28,29,32,33] # quello che ci serve\n","  \n","  new_seg = seg.copy()\n","  \n","  for i in range(new_seg.shape[0]):\n","    for j in range(new_seg.shape[1]):\n","      if new_seg[i][j] not in mo_id_to_color:\n","        new_seg[i][j] = 0\n","        \n","  return new_seg\n","           "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RbXZ_Rr-o5ps","colab_type":"code","colab":{}},"source":["def is_on_the_road(box, seg):\n","  x1, y1 = box[1], box[0]\n","  x2, y2 = box[3], box[2]\n","  width = abs(x2 - x1)\n","  height = abs(y2 - y1)\n","  \n","  THRESHOLD = 100\n","  \n","  road_pixel_counter = 0\n","  \n","  for i in range(y1, y2):\n","      for j in range(x1, x2):\n","        if seg[i][j] == 7 :\n","          road_pixel_counter = road_pixel_counter + 1\n","  print(road_pixel_counter)\n","          \n","  if road_pixel_counter > THRESHOLD:\n","    return True\n","\n","  return False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UYMNKiVsQW3b","colab_type":"code","colab":{}},"source":["def create_bounding_boxes(frame, seg):\n","  MINAREA = 1000\n","  MaxAREA = 1080*1920*0.80\n","  frame = img_to_array(frame)\n","  \n","  #clean_segmentation(seg)\n","  cleaned_seg = clean_segmentation(seg)\n","  \n","  map_labeled = measure.label(cleaned_seg, connectivity=1)\n","  for region in measure.regionprops(map_labeled):\n","    if region.area > MINAREA and region.area < MaxAREA :\n","        box = region.bbox\n","        p1 = (box[1], box[0])\n","        p2 = (box[3], box[2])\n","        \n","        if is_on_the_road(box, seg) == True:\n","          cv2.rectangle(frame, p1, p2, (77,255,9), 2)\n","        else:\n","          cv2.rectangle(frame, p1, p2, (255,255,255), 2)\n","        \n","        #vis_text(frame,label_names[seg_map[tuple(region.coords[0])]],(p1[0],p1[1]-10))\n","  \n","  return frame"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t6Napxp3YxVs","colab_type":"code","colab":{}},"source":["#Video frames extraction\n","from google.colab.patches import cv2_imshow\n","import cv2\n","import numpy as np\n","from skimage import measure \n","\n","# Create a VideoCapture object and read from input file\n","# If the input is the camera, pass 0 instead of the video file name\n","#os.chdir(\"dataset/\")\n","cap = cv2.VideoCapture(os.path.join(ROOT_DIR,'dataset/due.mp4'))\n","\n","# Check if camera opened successfully\n","if (cap.isOpened()== False): \n","  print(\"Error opening video stream or file\")\n","\n","counter = 0\n","  \n","# # Read until video is completed\n","while(cap.isOpened()):\n","\n","  ret, frame = cap.read()\n","  counter = counter + 1\n","  if ret == True:\n","    if counter == 100 :\n","      counter = 0\n","      \n","      img_masked, seg = pipeline(frame, return_seg=True)\n","      \n","      img_masked = create_bounding_boxes(img_masked, seg)\n","      \n","      cv2_imshow(cv2.cvtColor(img_masked, cv2.COLOR_RGB2BGR))\n","\n","#     # Press Q on keyboard to  exit\n","\n","\n","# # Break the loop\n","# else: \n","#   print(\"ret is False\")\n","\n","# When everything done, release the video capture object\n","cap.release()\n","\n","# Closes all the frames\n","cv2.destroyAllWindows()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v6jVevuiG9uc","colab_type":"code","colab":{}},"source":["#Video frames extraction\n","from google.colab.patches import cv2_imshow\n","import cv2\n","import numpy as np\n","from skimage import measure \n","\n","# Create a VideoCapture object and read from input file\n","# If the input is the camera, pass 0 instead of the video file name\n","#os.chdir(\"dataset/\")\n","cap = cv2.VideoCapture(os.path.join(ROOT_DIR,'dataset/due.mp4'))\n","\n","# Check if camera opened successfully\n","if (cap.isOpened()== False): \n","  print(\"Error opening video stream or file\")\n","\n","counter = 0\n","  \n","# # Read until video is completed\n","while(cap.isOpened()):\n","\n","  ret, frame = cap.read()\n","  counter = counter + 1\n","  if ret == True:\n","    if counter == 100 :\n","      counter = 0\n","      MINAREA = 1000\n","      MaxAREA = 1080*1920*0.80\n","      frame = img_to_array(frame)\n","      pipeline(frame, return_seg=False)\n","#       map_labeled = measure.label(seg, connectivity=1)\n","#       for region in measure.regionprops(map_labeled):\n","#           if region.area > MINAREA and region.area < MaxAREA :\n","#               box = region.bbox\n","#               p1 = (box[1], box[0])\n","#               p2 = (box[3], box[2])\n","#               cv2.rectangle(frame, p1, p2, (77,255,9), 2)\n","#     #           vis_text(frame,label_names[seg_map[tuple(region.coords[0])]],(p1[0],p1[1]-10))\n","#     s  cv2_imshow(cv2.cvtColor(seg, cv2.COLOR_RGB2BGR))\n","\n","\n","#     # Press Q on keyboard to  exit\n","    if cv2.waitKey(25) & 0xFF == ord('q'):\n","      break\n","\n","# # Break the loop\n","# else: \n","#   print(\"ret is False\")\n","\n","# When everything done, release the video capture object\n","cap.release()\n","\n","# Closes all the frames\n","cv2.destroyAllWindows()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IorZNsLRTVRG","colab_type":"code","colab":{}},"source":["for image_dir in ['stuttgart_00', 'stuttgart_01', 'stuttgart_02']:\n","    os.mkdir(f'outputs/{image_dir}')\n","    image_list = os.listdir(image_dir)\n","    image_list.sort()\n","    print(f'{len(image_list)} frames found')\n","    for i in tqdm(range(len(image_list))):\n","        try:\n","            test = load_img(f'{image_dir}/{image_list[i]}')\n","            test = img_to_array(test)\n","            segmap = pipeline(test, video=False, fname=f'{image_list[i]}', folder=image_dir)\n","            if segmap == False:\n","                break\n","        except Exception as e:\n","            print(str(e))\n","    clip = ImageSequenceClip(sorted(glob(f'outputs/{image_dir}/*')), fps=18, load_images=True)\n","    clip.write_videofile(f'{image_dir}.mp4')"],"execution_count":0,"outputs":[]}]}